// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel CSMain

// Output parameters
RWTexture2D<float4> Position;
RWTexture2D<float4> Direction;
RWTexture2D<float4> Color;
RWTexture2D<int> isComplete;
RWTexture2D<float> TimeStep;
RWTexture2D<float> ErrorTolerance;

// Input parameters
float4x4 _CameraToWorld;
float4x4 _CameraInverseProjection;
float3 _CameraPositionCartesian;
float timeStep;
float errorTolerance;
float horizonRadius;

float Dot(float4x4 g, float4 v1, float4 v2)
    {
        float dot = 0;

        [unroll]
        for(int a = 0; a < 4; a++)
        {
            for(int b = 0; b < 4; b++)
            {
                dot += g[a][b] * v1[a] * v2[b];
            }
        }
     
        return dot;
    }

    float4 vAdd(float4 v1, float4 v2)
    {
        float4 added;
        added[0] = v1[0] + v2[0];
        added[1] = v1[1] + v2[1];
        added[2] = v1[2] + v2[2];
        added[3] = v1[3] + v2[3];

        return added;
    }

    float4 vScale(float s, float4 v)
    {
        //float4 scaled = (s * v[0], s * v[1], s * v[2], s * v[3]);
        float4 scaled;
        scaled[0] = v[0] * s;
        scaled[1] = v[1] * s;
        scaled[2] = v[2] * s;
        scaled[3] = v[3] * s;
        return scaled;
    }

    float4 vNormalize(float4x4 g, float4 v)
    {
        float norm = sqrt(abs(Dot(g, v, v)));

        return vScale(1 / norm, v);
    }

    float Pow4(float input)
    {
        return input * input * input * input;
    }

    float4x4 Metric(float4 x)
    {
        float rho = sqrt((x[1] * x[1]) + (x[2] * x[2]) + (x[3] * x[3]));
        float rho_s = horizonRadius;
        float4x4 g;
        [unroll]
        for (int a = 0; a < 4; a++)
        {
            for (int b = 0; b < 4; b++)
            {
                g[a][b] = 0.0;
            }
        }
        g[0][0] = -(1 - rho_s / rho) / (1 + rho_s / rho) * (1 - rho_s / rho) / (1 + rho_s / rho);
        g[1][1] = Pow4((1 + rho_s / rho));
        g[2][2] = g[1][1];
        g[3][3] = g[1][1];

        return g;
    }

    float4x4 CameraTetrad(float4 x)
    {
        float4x4 tetrad;

        // float4 ep_x = (0.0, 1.0, 0.0, 0.0);
        // float4 ep_y = (0.0, 0.0, 1.0, 0.0);
        // float4 ep_z = (0.0, 0.0, 0.0, 1.0);

        // float4 ep_0 = (1.0, 0.0, 0.0, 0.0);

        float4 ep_x;
        float4 ep_y;
        float4 ep_z;
        float4 ep_0;

        ep_x[0] = 0.0;
        ep_x[1] = 1.0;
        ep_x[2] = 0.0;
        ep_x[3] = 0.0;

        ep_y[0] = 0.0;
        ep_y[1] = 0.0;
        ep_y[2] = 1.0;
        ep_y[3] = 0.0;

        ep_z[0] = 0.0;
        ep_z[1] = 0.0;
        ep_z[2] = 0.0;
        ep_z[3] = 1.0;

        ep_0[0] = 1.0;
        ep_0[1] = 0.0;
        ep_0[2] = 0.0;
        ep_0[3] = 0.0;

        float4x4 g = Metric(x);

        float4 e_0 = vNormalize(g, ep_0);

        float4 ep_1 = vAdd(ep_x, vScale(Dot(g, e_0, ep_x), e_0));

        float4 e_1 = vNormalize(g, ep_1);

        float4 ep_2 = vAdd(vScale(-Dot(g, e_1, ep_y), ep_y), vAdd(ep_y, vScale(Dot(g, e_0, ep_y), e_0)));

        float4 e_2 = vNormalize(g, ep_2);

        float4 ep_3 = vAdd(vScale(-Dot(g, e_2, ep_z), e_2), vAdd(vScale(-Dot(g, e_1, ep_z), e_1), vAdd(ep_z, vScale(Dot(g, e_0, ep_z), e_0))));

        float4 e_3 = vNormalize(g, ep_3);

        tetrad[0] = e_0;
        tetrad[1] = e_1;
        tetrad[2] = e_2;
        tetrad[3] = e_3;

        return tetrad;
    }

     float4 tetradDirection(float4 x, float3 omega)
     {
        float4 k;

        float4x4 e = CameraTetrad(x);

        float h = Metric(x)[2][2];

        k[0] = e[0][0] + omega[0] * e[0][1] + omega[1] * e[0][2] + e[0][3] * omega[2];
        k[1] = e[1][0] + omega[0] * e[1][1] + omega[1] * e[1][2] + e[1][3] * omega[2];
        k[2] = e[2][0] + omega[0] * e[2][1] + omega[1] * e[2][2] + e[2][3] * omega[2];
        k[3] = e[3][0] + omega[0] * e[3][1] + omega[1] * e[3][2] + e[3][3] * omega[2];

        //return float4(0.0, k[1], k[2], k[3]);
        return k;
     }

[numthreads(8,8,1)]
void CSMain (uint3 id : SV_DispatchThreadID)
{
    // Initialize pixel color
    float3 pixelColor;

    // Get the dimensions of the RenderTexture
    uint width, height;
    Position.GetDimensions(width, height);

    // Transform pixel to [-1,1] range
    float2 uv = float2((id.xy + float2(0.5f, 0.5f)) / float2(width, height) * 2.0 - 1.0);

    // Invert the perspective projection of the view-space position
    float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0, 1.0)).xyz;

    // Transform the direction from camera to world space and normalize
    direction = mul(_CameraToWorld, float4(direction, 0.0)).xyz;
    direction = normalize(direction);

    // Pass direction to result
    Position[id.xy] = float4(0.0, _CameraPositionCartesian);
    Direction[id.xy] = float4(0.0, -direction);
    //Direction[id.xy] = tetradDirection(float4(1.0, _CameraPositionCartesian), -direction);
    Color[id.xy] = float4(0.0, 0.0, 0.0, 0.0);
    isComplete[id.xy] = 0;
    TimeStep[id.xy] = timeStep;
    ErrorTolerance[id.xy] = errorTolerance;
}
